\section{Discussion}
\label{sec:discussion}

\subsection{Why Self-Supervised Learning Improves Low-Label Performance}
\label{subsec:why_ssl_works}

Our results demonstrate consistent improvements from self-supervised pretraining across all tasks, with the most substantial gains (6.8--29.1\%) occurring when labeled data is severely limited (10\% training fraction). This effectiveness stems from three complementary mechanisms.

\textbf{Physics-meaningful pretext tasks:} Unlike generic graph {SSL} methods that mask arbitrary node features~\cite{hou2022graphmae,thakoor2022bgrl}, our masked injection reconstruction objective directly targets power system quantities governed by physical laws. To reconstruct a masked bus's active power injection $P_i$, the encoder must implicitly learn Kirchhoff's Current Law: power balance requires that injections equal the net sum of flows on connected lines. Similarly, masked edge parameter reconstruction (reactance, thermal ratings) forces the model to learn which lines connect which buses with which impedances, capturing the grid's electrical topology structure; our ablation (Table~\ref{tab:masking_ablation}) shows this is non-trivial and provides complementary benefit to node reconstruction. This contrasts with supervised learning, which directly observes voltage or flow labels, potentially enabling shortcuts that bypass physical understanding. Self-supervised reconstruction cannot exploit such shortcuts---the model must learn the underlying physics to succeed at the pretext task.

\textbf{Representation initialization and loss landscape geometry:} Neural network training dynamics are heavily influenced by initialization~\cite{glorot2010understanding}. Random initialization places parameters in arbitrary regions of the loss landscape, requiring supervised gradient descent to navigate from scratch. In low-label regimes, sparse supervision provides weak gradients that may converge to poor local minima or exhibit high variance across random seeds (as observed with {IEEE} 118-bus scratch training at 10\% labels: F1 variance $\pm$0.243). Self-supervised pretraining moves encoder parameters into favorable loss landscape regions where the model has already learned to represent grid topology, electrical coupling strengths, and power balance relationships. Subsequent fine-tuning on task-specific labels then requires only modest adjustments rather than learning representations from scratch, enabling more reliable and sample-efficient convergence.

\textbf{Shared structural patterns across tasks:} Cascade prediction, power flow approximation, and line flow estimation all depend fundamentally on understanding how power transfers through grid topology. A bus's voltage magnitude is determined by its injection and connected lines' impedances; a line's power flow depends on connected buses' voltages; a cascade propagates along paths of overloaded lines connecting vulnerable buses. Our {SSL} pretraining captures these shared structural patterns by forcing the encoder to predict local electrical quantities from neighborhood context, yielding representations that transfer effectively across multiple downstream tasks. This explains why {SSL} benefits persist even at 100\% labels, albeit diminished: the pretrained encoder has learned complementary features beyond task-specific supervision.

\subsection{Operational Implications and Deployment Considerations}
\label{subsec:operational}

Deploying machine learning models for real-time grid operations requires careful consideration of what information is observable without computationally expensive simulations. Our approach is designed for practical deployment scenarios where only measurements and network parameters are available, not solutions from conventional solvers.

\textbf{Observability assumptions:} At inference time, our models assume access to: (1)~Bus-level measurements of active and reactive power injections ($P_{\text{net}}$, $S_{\text{net}}$) from supervisory control and data acquisition ({SCADA}) systems or phasor measurement units ({PMU}s), (2)~Network topology and line parameters (conductance, susceptance, reactance, thermal ratings) from grid databases, and (3)~For cascade prediction and line flow tasks, current bus voltage magnitudes from state estimation. Critically, we do \emph{not} assume access to power flow solutions, optimal dispatch decisions, or cascade simulation outputs at inference time---these are the expensive computations our models replace. For power flow prediction specifically, voltage magnitudes are excluded from input features since they constitute the prediction target.

\textbf{No-oracle deployment:} Unlike some prior work that assumes oracle knowledge of future grid states or failure outcomes~\cite{donon2020neural}, our models make predictions based solely on pre-event measurements. For cascade prediction, we observe the grid state before a contingency occurs and predict whether a cascade will result, without knowing which specific lines will fail or having access to intermediate cascade propagation states. This no-oracle constraint is essential for practical deployment: operators need to assess cascade risk \emph{before} taking preventive actions, not after the cascade has already begun.

\textbf{Computational efficiency:} Self-supervised pretraining is performed offline once per task per grid, requiring approximately 30 minutes on a single {GPU} for {IEEE} 24-bus and 2 hours for {IEEE} 118-bus. Once pretrained, the encoder can be fine-tuned for multiple downstream tasks without repeating pretraining. Inference is extremely fast: cascade prediction for a single grid state requires $<$10 milliseconds on {CPU}, enabling real-time contingency screening. Power flow and line flow prediction similarly achieve sub-second inference times, orders of magnitude faster than iterative numerical solvers that require seconds to minutes per solve.

\subsection{Scalability Findings: IEEE 118-Bus System}
\label{subsec:scalability_discussion}

The {IEEE} 118-bus results reveal a nuanced but operationally critical finding: self-supervised pretraining is most valuable when labeled data is extremely scarce relative to problem difficulty. At 10\% labeled data on the {IEEE} 118-bus system, scratch training exhibits catastrophic instability with F1 variance $\pm$0.243---some random seeds converge to reasonable performance (F1 $\approx$ 0.60), while others fail completely (F1 $\approx$ 0.05). This variance indicates that scratch training in severe low-label regimes is unreliable: deployment success depends on fortunate random initialization, an unacceptable risk for safety-critical infrastructure.

Self-supervised pretraining eliminates this instability: all five random seeds converge to F1 = 0.87 $\pm$ 0.051, providing consistent performance regardless of initialization. This stability advantage diminishes at higher label fractions---by 20\% labeled data, both scratch and {SSL} methods achieve reliable convergence (F1 $>$ 0.83) with low variance. The practical implication is clear: when labeled cascade data is expensive or impossible to obtain (e.g., rare blackout events with limited historical records), {SSL} pretraining provides the reliability necessary for operational deployment. When labeled data is abundant ($>$20\% of available samples), both approaches work well, and the choice between them becomes less critical.

\textbf{Class imbalance interaction:} The {IEEE} 118-bus cascade dataset exhibits severe class imbalance (approximately 5\% positive class rate), compounding the low-label challenge. With only 10\% labeled data, scratch training observes fewer than 500 positive (cascade) examples within the labeled subset of approximately 9,200 samples---insufficient for learning rare failure patterns. Self-supervised pretraining mitigates this by learning grid structure from \emph{all} unlabeled training data, not just the small labeled subset, providing a representation foundation that requires fewer labeled cascade examples to achieve reliable classification.

\subsection{Data-Regime Dependence: When SSL Helps vs. Hurts}
\label{subsec:data_regime}

A notable finding from our {IEEE} 118-bus regression experiments (Section~\ref{subsec:regression_118}) is the emergence of data-regime dependence: {SSL} pretraining provides substantial benefits at low label fractions (+19.7\% to +31.8\% at 10\% labels) but becomes a \textit{constraint} at full data availability ($-$4.4\% to $-$31.4\% at 100\% labels). This pattern differs markedly from cascade prediction, where {SSL} maintains modest advantages even at 100\% labels.

\textbf{Hypothesis---representation lock-in:} We hypothesize that {SSL} pretraining optimizes encoder weights for a general-purpose objective (reconstructing masked power injections and line parameters), creating representations well-suited for diverse downstream tasks but potentially suboptimal for any specific task. When labeled data is scarce, this general foundation provides crucial inductive bias that accelerates learning and improves generalization. However, when labeled data is abundant, scratch training can learn highly task-specific representations that exploit patterns unique to the particular prediction objective. For regression tasks like power flow and line flow, where outputs are continuous values with specific numerical relationships to inputs, task-specific specialization may matter more than for classification tasks where decision boundaries are more abstract.

\textbf{Task-dependent transfer:} The effect is more pronounced for power flow ($-$31.4\% at 100\%) than line flow ($-$4.4\%). Power flow prediction targets bus-level voltage magnitudes, requiring node-level outputs that depend on global power balance relationships. Line flow prediction targets edge-level quantities that align more directly with our edge-focused {SSL} pretext task (masked edge parameter reconstruction). This suggests that {SSL} transfer effectiveness depends on alignment between pretext and downstream task granularity.

\textbf{Deployment recommendation:} These findings inform practical deployment strategies. For low-label scenarios ($\leq$20\% available labels), {SSL} pretraining is strongly recommended across all tasks. For high-label scenarios ($\geq$50\% labels) on regression tasks, practitioners should evaluate both pretrained and scratch models on validation data before selecting the deployment model. Standard {SSL} mitigations for representation lock-in include: (1)~using a projection head during pretraining that is discarded during fine-tuning~\cite{chen2020simple}, preventing task-irrelevant features from being encoded in the backbone, and (2)~applying differential learning rates with lower rates for pretrained encoder layers, allowing gradual adaptation without catastrophic forgetting. Progressive fine-tuning strategies that gradually unfreeze encoder layers may also allow escaping {SSL}-learned representations when beneficial, combining the stability of pretrained initialization with the flexibility of scratch training. Future work could evaluate whether these techniques improve high-label regime performance on power system regression tasks.

\subsection{Limitations and Future Directions}
\label{subsec:limitations}

While our results demonstrate clear benefits of physics-guided self-supervised learning, several limitations warrant discussion and suggest directions for future research.

\textbf{Single benchmark evaluation:} All experiments use the {PowerGraph} benchmark~\cite{varbella2024powergraph} on simulated {IEEE} test systems. Validation on real utility datasets with operational measurements, measurement noise, missing data, and dynamic topology changes is essential before deployment. Real grids exhibit complexities not captured in simulation: communication delays, bad data from faulty sensors, topology errors in network models, and time-varying renewable generation. Transfer learning experiments demonstrating that models pretrained on simulated data can fine-tune effectively on small real-world labeled datasets would strengthen deployment confidence.

\textbf{Node feature representation:} Following the {PowerGraph} benchmark specification, node features use apparent power magnitude $S_{\text{net}}$ rather than signed reactive power $Q_{\text{net}}$. While $S_{\text{net}} = \sqrt{P^2 + Q^2}$ loses the sign distinguishing inductive from capacitive loads, this information is partially recoverable: (1)~reactive power flow $Q_{ij}$ on edges retains sign and is used for line flow prediction, and (2)~the relationship between $P_{\text{net}}$, $S_{\text{net}}$, and neighboring bus voltages allows implicit learning of power factor effects. Future work could investigate whether including signed $Q_{\text{net}}$ as an additional node feature improves voltage prediction accuracy, particularly for grids with significant reactive power compensation.

\textbf{Simulated operating state features:} The {PowerGraph} benchmark provides node features (including $S_{\text{net}}$) extracted from simulated {AC} power flow operating states. For {PV} (generator) buses, reactive power $Q$ is a dependent variable determined during power flow solution, meaning $S_{\text{net}} = \sqrt{P^2 + Q^2}$ reflects the solved operating point rather than pre-contingency setpoints. This is inherent to simulation-based benchmarks that provide grid snapshots from converged power flow solutions. Real-world deployment would use {SCADA}/{PMU} measurements of actual operating conditions, which similarly reflect the current (solved) system state rather than hypothetical pre-solve quantities. Future work could investigate whether using only $P_{\text{net}}$ for {PV} buses improves generalization to unseen operating conditions, or whether the current formulation's implicit encoding of operating state is beneficial for learning realistic grid behavior.

\textbf{Bus type and voltage angle representation:} Following the {PowerGraph} benchmark specification, our formulation does not include explicit bus type indicators ({PV}/{PQ}/Slack) in node features. In standard {AC} power flow, {PV} buses have specified voltage magnitude (generator setpoint) while {PQ} buses have voltage as a state variable. This omission renders the power flow prediction problem technically ill-posed in the classical sense, as voltage setpoints for {PV} buses are unspecified. Without bus type encoding, the model must implicitly learn bus characteristics from injection patterns---generators typically exhibit large positive active power injections, while loads show negative injections---which represents a more challenging learning task compared to traditional solvers that receive explicit bus type specifications. Additionally, voltage angles are not included as inputs or evaluated as outputs; the model predicts only voltage magnitudes. While angles could be inferred from the trained model (our architecture supports angle prediction via sin/cos outputs), the {PowerGraph} benchmark does not provide angle ground truth for evaluation. Future work could extend the benchmark to include bus type encoding and angle targets, enabling more physically complete power flow surrogate models.

\textbf{Static topology assumption:} Our current framework assumes fixed grid topology during training and inference. Real power systems undergo frequent topology changes due to maintenance outages, equipment failures, and switching operations for loss minimization. Extending our approach to handle dynamic topology---for example, via graph structure learning~\cite{franceschi2019learning} or topology-conditional embeddings---would improve practical applicability. Additionally, investigating how well models generalize to unseen topologies (e.g., training on {IEEE} 24-bus, testing on {IEEE} 30-bus) would clarify the transferability of learned physics principles across grid structures.

\textbf{Limited out-of-distribution evaluation:} We evaluated robustness only under load scaling (1.0--1.3$\times$ nominal injections). Other critical distribution shifts remain unexplored: (1)~Measurement noise and missing data, (2)~Seasonal and diurnal load pattern variations, (3)~High renewable penetration with intermittent generation, (4)~Topology perturbations (line outages), and (5)~Extreme weather events causing correlated failures. A comprehensive robustness evaluation across multiple {OOD} dimensions is necessary to establish reliability bounds for operational deployment. Our load scaling results (Table~\ref{tab:robustness}) use 5 random seeds matching our main experiments, providing statistical confidence in the observed robustness patterns.

\textbf{Computational cost of pretraining:} While inference is fast, self-supervised pretraining requires 30 minutes to 2 hours of {GPU} time depending on grid size. For utilities with hundreds of distinct network models (e.g., different seasonal configurations, multiple voltage levels), pretraining all models could incur significant computational cost. Investigating few-shot transfer learning---pretraining once on a large representative grid, then fine-tuning with minimal data on similar grids---could amortize pretraining costs across multiple deployment scenarios.

\textbf{Explainability depth:} Our Integrated Gradients evaluation demonstrates that the model correctly ranks critical edges (0.93 {AUC-ROC}), but does not provide \emph{mechanistic} explanations of \emph{why} specific lines are vulnerable. Causal discovery methods~\cite{pearl2009causality} or attention mechanism interpretation~\cite{vaswani2017attention} could yield deeper insights into learned failure propagation patterns, enabling operators to understand not just \emph{which} lines matter but \emph{how} cascades propagate through grid topology.

\textbf{Decomposing physics and {SSL} contributions:} Our framework combines two sources of improvement: physics-guided encoder architecture (electrically-parameterized message passing) and {SSL} pretraining (masked reconstruction). While we ablate encoder architectures in Section~\ref{subsec:ablation} and compare {SSL} vs. scratch training throughout, we do not directly compare our masked reconstruction against alternative {SSL} strategies (e.g., contrastive learning, link prediction). The masked reconstruction approach follows {GraphMAE}~\cite{hou2022graphmae} applied to power-relevant features; investigating whether physics-specific pretext tasks (e.g., predicting power balance violations or line flow directions) would outperform generic masking remains future work. Nonetheless, our ablations demonstrate that both encoder architecture and pretraining contribute meaningfully to low-label performance.

\textbf{Ablation completeness:} Our ablation strategy follows standard practice by varying one factor at a time: encoder architecture under scratch training (Table~\ref{tab:encoder_ablation}) and pretraining strategy with our physics-guided encoder (Tables~\ref{tab:cascade_24}--\ref{tab:line_flow}). A full factorial design crossing all encoder types with all pretraining strategies would require $3 \times 3 = 9$ conditions (physics/vanilla/{GCN} encoders $\times$ our {SSL}/generic {SSL}/scratch). While we do not run all combinations, our existing ablations demonstrate that both factors contribute: physics-guided encoding provides +17.6\% over {GCN} at 10\% labels, and {SSL} pretraining provides +6.8\% over scratch with the same encoder. We expect {SSL} benefits to transfer to other encoders, as masked reconstruction is architecture-agnostic; validating this expectation remains future work.

\textbf{Learned vs.\ fixed physics weights:} Our edge weighting $y_{ij}$ is learned from electrical features (conductance, susceptance, reactance, thermal ratings) rather than directly using admittance magnitudes $|Y_{ij}|$ or inverse reactance $1/|x_{ij}|$. This design choice trades strict physics fidelity for task-adaptive flexibility: the model can learn which electrical properties matter most for each prediction task, rather than assuming a fixed relationship. Our encoder ablation (Table~\ref{tab:encoder_ablation}) demonstrates that this electrically-parameterized approach outperforms both unweighted message passing and standard {GCN} at low label fractions. Future work could compare learned weights against fixed physics weights ($y_{ij} \propto 1/|x_{ij}|$) to quantify the trade-off between physics fidelity and task adaptability.

\textbf{Static edge parameters:} On fixed-topology benchmark grids, line parameters (reactance $x_{ij}$, thermal rating) are static infrastructure constants that do not vary across operating samples---only power injections and resulting flows change with load conditions. One might expect edge reconstruction to reduce to trivial memorization of static parameters. However, our masking strategy ablation (Table~\ref{tab:masking_ablation}) reveals a surprising finding: edge-only and node-only masking achieve \emph{identical} downstream performance (F1 = 0.882 at 10\% labels), both substantially outperforming scratch training (F1 = 0.773). This suggests that reconstructing static edge parameters from masked context is \emph{not} trivial---the encoder must still learn meaningful topological representations to predict which lines connect which buses with which impedances. The combined approach achieves best results (F1 = 0.895), indicating complementary information from node and edge signals. Future work could investigate whether time-varying edge features (line temperatures, real-time loading from {SCADA}) further improve pretraining quality.

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{figures/explainability_example.pdf}
\caption{Explainability visualization: Integrated Gradients correctly identifies critical transmission lines (red = high importance) that align with ground-truth failure explanations, achieving 0.93 AUC-ROC fidelity.}
\label{fig:explainability}
\end{figure}
